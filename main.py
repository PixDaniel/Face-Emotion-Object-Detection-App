# main.py
import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image

st.set_page_config(
    page_title="Face Emotion Recognition & Object Detection In Real-Time",
    page_icon="üòä",
    layout="wide"
)

st.markdown("""
    <style>
    .title {
        color: #1e81b0;
        font-size: 3em;
        text-align: center;
    }
    .sidebar .sidebar-content {
        background-color: #e6f3ff;
    }
    </style>
    """, unsafe_allow_html=True)

st.markdown('<h1 class="title">Face Emotion Recognition</h1>', unsafe_allow_html=True)

# Initialisation du mod√®le
@st.cache_resource
def load_model():
    return YOLO("/models_detection/yolov8l.pt")

model = load_model()

with st.sidebar:
    st.header("Configuration")
    confidence = st.slider("Seuil de confiance", 0.0, 1.0, 0.5)
    st.markdown("---")
    st.info("Cette application d√©tecte les √©motions en temps r√©el √† l'aide d'un mod√®le YOLO entra√Æn√©.")

# Gestion de la webcam
run = st.checkbox("Activer la webcam")
FRAME_WINDOW = st.image([])

# Capture vid√©o
cap = cv2.VideoCapture(0)

while run:
    ret, frame = cap.read()
    if not ret:
        st.error("Erreur d'acc√®s √† la webcam")
        break
    
    # Conversion des couleurs
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(frame)
    
    # D√©tection avec YOLO
    results = model.predict(pil_image, conf=confidence)
    annotated_frame = results[0].plot(line_width=2, font_size=10)
    
    # Affichage du r√©sultat
    FRAME_WINDOW.image(annotated_frame)

if not run:
    cap.release()
    st.warning("Webcam d√©sactiv√©e")